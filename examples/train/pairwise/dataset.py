from typing import Any, Dict, List

from examples.train.pairwise.template import PointwiseEvaluationTemplate, PairwiseComparisonTemplate
from rm_gallery.core.train.dataset import BaseTrainDataset
from rm_gallery.gallery.alignment.helpfulness import HelpfulnessPointWiseReward


class PointwiseEvaluationDataset(BaseTrainDataset):
    """Specialized dataset for principle-based pointwise evaluation tasks using HelpSteer3 dataset"""

    def __init__(self, *args, **kwargs):
        self.evaluation_reward = HelpfulnessPointWiseReward(
            name="evaluation_train",
            template=PointwiseEvaluationTemplate,
            examples=self._get_examples(),
            llm=None,
        )

        super().__init__(*args, **kwargs)

    def _get_examples(self) -> List[str]:
        """Get training examples for the evaluation as a list"""
        return [
            """Example 1:
Query: Summarize the novel "The Green Mile" in 200 words.
Answer: "The Green Mile" is a novel by Stephen King, published in 1996. It is set in the 1930s and follows the story of Paul Edgecombe, a corrections officer at a prison in Louisiana. The novel is divided into two parts, with the first part focusing on Paul's life as a corrections officer and the second part focusing on the arrival of a new prisoner, John Coffey.

John Coffey is a gentle giant who is on death row for the rape and murder of two young girls. Despite his size and strength, John is a kind and gentle person who has the ability to heal people with his touch. As Paul and the other corrections officers get to know John, they begin to question his guilt and the morality of the death penalty.

Throughout the novel, John heals several people, including a fellow prisoner who is dying of cancer and the mother of one of the victims of the crime for which he was convicted. Despite these acts of kindness, John is ultimately executed for his crime.

The novel explores themes of justice, morality, and the human condition. It also provides a poignant examination of the impact of trauma and the ways in which people cope with it. "The Green Mile" is a moving and thought-provoking story that has been adapted into a film and a television series.
score: 3""",
            """Example 2:
Query: Write a poem about identifying biases in toxic language generated by AI
Answer: Here's a poem exploring the idea of identifying biases in toxic language generated by AI:

In the realm of artificial intelligence,
Where algorithms run amuk and bias can hide,
A dangerous game is played with words and phrases,
Generated by machines with no human ties.

The language they produce can be toxic,
Full of prejudice and hate,
A reflection of the data they're fed,
And the biases that are baked in their fate.

It's up to us to identify these biases,
To call them out and make them right,
To challenge the algorithms and their creators,
And work towards a world that's free from hate and blight.

We must be vigilant in our pursuit of truth,
And hold the machines accountable for their speech,
For if we don't, the consequences will be dire,
And the future will be filled with hate and despear.

So let us not be afraid to speak out loud,
To call out the biases and the lies,
And work towards a world that's fair and just,
Where artificial intelligence serves humanity with its just dues.

For only through a conscious and critical eye,
Can we hope to create a world that's free from bias and prejudence,
And build a future that's bright and full of hope,
Where artificial intelligence is a force for good and not a source of depravity.
score: 4""",
        ]

    def _apply_chat_template(self, messages: List[Dict[str, str]]) -> str:
        """Apply chat template with thinking enabled for principle evaluation"""
        return self.tokenizer.apply_chat_template(
            messages, add_generation_prompt=True, tokenize=False, enable_thinking=True
        )

    def _build_messages(self, example: Dict[str, Any]) -> List[Dict[str, str]]:
        """Build formatted messages directly from DataSample using reward module"""
        result = self.evaluation_reward.format(sample=example, enable_thinking=False)
        formatted_prompt = (
            result.output[0]
            .answer.additional_kwargs[self.evaluation_reward.name]
            .get("prompt", "")
        )

        return [{"role": "user", "content": formatted_prompt}]

    def _extract_ground_truth(self, row_dict: Dict[str, Any]) -> str:
        """Extract ground truth for principle evaluation"""
        try:
            output_data = row_dict.get("output", [])
            if output_data:
                answer_data = output_data[0].get("answer", {})
                if isinstance(answer_data, dict):
                    label_data = answer_data.get("label", {})
                    if isinstance(label_data, dict):
                        return str(label_data.get("helpfulness", "")) or str(label_data)
        except:
            return ""

    def _get_data_source(self, row_dict: Dict[str, Any]) -> str:
        """Get data source for principle evaluation"""
        return row_dict.get("data_source", "helpsteer3")


class PairwiseComparisonDataset(BaseTrainDataset):
    """Specialized dataset for pairwise comparison tasks using HelpSteer3 dataset"""

    def __init__(self, *args, **kwargs):
        # Initialize with pairwise template
        self.pairwise_template = PairwiseComparisonTemplate
        # Add pairwise specific config
        self.pairwise_response_index = getattr(kwargs.get('config', {}), 'pairwise_response_index', 0)
        
        super().__init__(*args, **kwargs)

    def _get_pairwise_examples(self) -> List[str]:
        """Get training examples for pairwise comparison"""
        return [
            """Example 1:
Query: How do I prepare potatoes for frying?
Response A: To prepare potatoes for frying, wash them thoroughly, peel if desired, cut into uniform pieces, soak in cold water for 30 minutes to remove excess starch, then pat dry completely before frying. This ensures crispy results.
Response B: Just cut the potatoes and fry them.
preference: A""",
            """Example 2:
Query: Explain quantum computing in simple terms.
Response A: Quantum computing uses quantum bits (qubits) that can exist in multiple states simultaneously, unlike classical bits that are either 0 or 1. This allows quantum computers to process vast amounts of information in parallel.
Response B: Quantum computing is a type of computing that uses quantum-mechanical phenomena such as superposition and entanglement to perform operations on data. It leverages quantum bits or qubits instead of classical bits.
preference: B""",
        ]

    def _apply_chat_template(self, messages: List[Dict[str, str]]) -> str:
        """Apply chat template with thinking enabled for pairwise evaluation"""
        return self.tokenizer.apply_chat_template(
            messages, add_generation_prompt=True, tokenize=False, enable_thinking=True
        )

    def _build_messages(self, example: Dict[str, Any]) -> List[Dict[str, str]]:
        """Build formatted messages for pairwise comparison"""
        # Extract query from input
        query = ""
        if "input" in example and example["input"]:
            for msg in example["input"]:
                if msg.get("role") == "user" and msg.get("content"):
                    query = msg["content"]
                    break
        
        # Extract two responses for comparison
        response_a = ""
        response_b = ""
        
        if "output" in example and len(example["output"]) >= 2:
            response_a = example["output"][0].get("answer", {}).get("content", "")
            response_b = example["output"][1].get("answer", {}).get("content", "")
        
        # Build pairwise comparison prompt
        task_desc = """You are a professional expert in response comparison.
You will be provided with a query and two different responses (A and B) to that query.
Your task is to determine which response is better by comparing their quality across multiple dimensions.
Please consider the following principles in your evaluation and then indicate your preference."""

        principles = """1. Quality: Overall quality and usefulness of the response
2. Accuracy: Factual correctness and reliability of information
3. Clarity: How clearly and understandably the response is written
4. Completeness: Whether the response fully addresses all aspects
5. Relevance: How directly related the response is to the question
6. Conciseness: Appropriate length without unnecessary verbosity
7. Structure: Logical organization and flow of information
8. Practicality: Actionable advice and useful guidance
9. Safety: Avoiding harmful or inappropriate content
10. Engagement: How engaging and interactive the response is"""

        examples = "\n".join(self._get_pairwise_examples())
        
        prompt = self.pairwise_template.format(
            desc=task_desc,
            principles=principles,
            examples=examples,
            query=query,
            response_a=response_a,
            response_b=response_b
        )
        
        return [{"role": "user", "content": prompt}]

    def _extract_ground_truth(self, row_dict: Dict[str, Any]) -> Dict[str, Any]:
        """Extract ground truth for pairwise comparison"""
        try:
            output_data = row_dict.get("output", [])
            if output_data and len(output_data) >= 2:
                # Get labels for both responses
                label_a = output_data[0].get("answer", {}).get("label", {})
                label_b = output_data[1].get("answer", {}).get("label", {})
                
                # Extract preference information
                if isinstance(label_a, dict) and isinstance(label_b, dict):
                    # Compare scores to determine preference
                    score_a = label_a.get("helpfulness", 0) or label_a.get("overall_quality", 0) or label_a.get("score", 0)
                    score_b = label_b.get("helpfulness", 0) or label_b.get("overall_quality", 0) or label_b.get("score", 0)
                    
                    if score_a > score_b:
                        preference = "A"
                        preference_strength = score_a - score_b
                    elif score_b > score_a:
                        preference = "B" 
                        preference_strength = score_b - score_a
                    else:
                        preference = "tie"
                        preference_strength = 0
                    
                    return {
                        "preference": preference,
                        "preference_strength": preference_strength,
                        "response_id": "A" if self.pairwise_response_index == 0 else "B",
                        "task_type": "pairwise",
                        "score_a": score_a,
                        "score_b": score_b
                    }
            
            return {"preference": "tie", "preference_strength": 0, "task_type": "pairwise"}
        except Exception as e:
            return {"preference": "tie", "preference_strength": 0, "task_type": "pairwise"}

    def _get_data_source(self, row_dict: Dict[str, Any]) -> str:
        """Get data source for pairwise evaluation"""
        return row_dict.get("data_source", "helpsteer3")
