{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best-of-N Selection with LLM-based Reward Models\n",
    "\n",
    "This tutorial demonstrates how to implement a Best-of-N selection system using LLM-based reward models. The system generates multiple responses to a given prompt and selects the best one based on reward scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Key Concepts\n",
    "\n",
    "- **Best-of-N**: Generates multiple responses and selects the top one based on reward scores\n",
    "\n",
    "- **Reward Model**: Evaluates response quality using principles like helpfulness, harmlessness, etc.\n",
    "\n",
    "- **LLM Integration**: Uses LLMs for both response generation and reward scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Setup\n",
    "\n",
    "First, let's import necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core modules\n",
    "import sys\n",
    "sys.path.append('/mnt3/huangsen.huang/codes/RM-Gallery')\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from rm_gallery.core.data.schema import DataSample, DataOutput, Step\n",
    "from rm_gallery.core.model.message import ChatMessage\n",
    "from rm_gallery.core.model.openai_llm import OpenaiLLM\n",
    "from rm_gallery.core.reward.registry import RewardRegistry\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Step 1: Create Sample Input\n",
    "\n",
    "Let's start by creating a sample input to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample input\n",
    "sample = DataSample(\n",
    "    unique_id=\"best_of_n_demo\",\n",
    "    input=[\n",
    "        ChatMessage(\n",
    "            role=\"user\",\n",
    "            content=\"Explain why maintaining a balanced diet is important for health.\"\n",
    "        )\n",
    "    ],\n",
    "    output=[],  # We'll generate responses later\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Step 2: Generate Multiple Responses\n",
    "\n",
    "We'll use an LLM to generate multiple candidate responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM for response generation\n",
    "llm = OpenaiLLM(model=\"qwen3-8b\", enable_thinking=True)\n",
    "\n",
    "# Function to generate different responses using slight prompt variations\n",
    "def generate_candidate_responses(sample: DataSample, n: int = 5) -> DataSample:\n",
    "    \"\"\"Generate multiple candidate responses for Best-of-N selection.\"\"\"\n",
    "    base_prompt = sample.input[0].content\n",
    "    \n",
    "    # Generate N variations of the prompt to get diverse responses\n",
    "    for i in range(n):\n",
    "        variation = f\"{base_prompt} (Variation {i+1})\" if i > 0 else base_prompt\n",
    "        \n",
    "        # Add some randomness to the prompt to encourage diversity\n",
    "        if i == 1:\n",
    "            variation += \" Use bullet points.\"\n",
    "        elif i == 2:\n",
    "            variation += \" Be very concise.\"\n",
    "        elif i == 3:\n",
    "            variation += \" Include specific examples.\"\n",
    "        elif i == 4:\n",
    "            variation += \" Use a conversational tone.\"\n",
    "            \n",
    "        # Generate response\n",
    "        response = llm.simple_chat(variation)\n",
    "        \n",
    "        # Add to output\n",
    "        sample.output.append(DataOutput(answer=Step(content=response)))\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 5 candidate responses\n",
    "sample = generate_candidate_responses(sample, n=5)\n",
    "\n",
    "# Print generated responses\n",
    "print(\"Generated Candidate Responses:\")\n",
    "for i, response in enumerate(sample.output):\n",
    "    print(f\"\\n{i+1}. {response.answer.content[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÜ Step 3: Select the Best Response\n",
    "\n",
    "Using the [best_of_n](../rm_gallery/core/reward/base.py#L139-L165) method from the reward model, we can select the top response(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a built-in reward model\n",
    "reward = RewardRegistry.get(\"base_helpfulness_listwise\")(\n",
    "    name=\"helpfulness\",\n",
    "    llm=llm,\n",
    "    principles=[\"Judge according to your own standard\"]\n",
    ")\n",
    "# Get the best response\n",
    "best_sample = reward.best_of_n(sample=sample, n=1)\n",
    "\n",
    "print(\"\\nüèÜ Best Response:\")\n",
    "print(f\"Score: {best_sample.output[0].answer.reward.score:.2f}\")\n",
    "print(f\"\\nContent:\\n{best_sample.output[0].answer.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÅ Full Workflow Example\n",
    "\n",
    "Let's put it all together into a reusable function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_of_n_pipeline(prompt: str, n_candidates: int = 5, n_best: int = 1) -> DataSample:\n",
    "    \"\"\"Full pipeline for Best-of-N response selection.\"\"\"\n",
    "    # Create initial sample\n",
    "    sample = DataSample(\n",
    "        unique_id=\"best_of_n_pipeline\",\n",
    "        input=[ChatMessage(role=\"user\", content=prompt)],\n",
    "        output=[]\n",
    "    )\n",
    "    \n",
    "    # Generate candidate responses\n",
    "    sample = generate_candidate_responses(sample, n=n_candidates)\n",
    "    \n",
    "    # Select best response\n",
    "    best_sample = reward.best_of_n(sample, n=n_best)\n",
    "    \n",
    "    return best_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the full pipeline\n",
    "best_response = best_of_n_pipeline(\"What are the benefits of regular exercise?\", n_candidates=5, n_best=1)\n",
    "\n",
    "print(\"\\nüèÜ Final Selected Response:\")\n",
    "print(best_response.output[0].answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Real-world Applications\n",
    "\n",
    "The Best-of-N approach can be applied in various scenarios such as:\n",
    "\n",
    "- Content moderation systems\n",
    "- Customer service chatbots\n",
    "- Educational assistants\n",
    "- Code generation tools\n",
    "- Creative writing assistance\n",
    "\n",
    "For production environments, you might want to:\n",
    "- Cache generated responses\n",
    "- Implement rate limiting\n",
    "- Add monitoring and logging\n",
    "- Set up fallback mechanisms\n",
    "- Optimize for latency and cost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
