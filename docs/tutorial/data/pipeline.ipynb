{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Module\n",
    "\n",
    "## Overview\n",
    "\n",
    "The Data Module provides a complete data processing solution covering the entire lifecycle from data loading, preprocessing, quality annotation to export. This module supports multiple operation modes and can flexibly combine different data processing components to meet various data processing scenario requirements.\n",
    "\n",
    "## System Architecture\n",
    "\n",
    "### Core Components\n",
    "\n",
    "The Data Module adopts a modular design consisting of five core components:\n",
    "\n",
    "1. **Load Module**\n",
    "   - Supports local files and remote data sources (such as HuggingFace Hub)\n",
    "   - Supports multiple data formats: parquet, jsonl, json, etc.\n",
    "   - Built-in data source adapters: rewardbench, chatmessage, prmbench, etc.\n",
    "   - Supports data splitting and sampling limits\n",
    "\n",
    "2. **Process Module**\n",
    "   - Configurable data processing pipeline\n",
    "   - Built-in filters: text length filtering, conversation turn filtering, etc.\n",
    "   - Integrated data-juicer advanced data cleaning operators\n",
    "   - Supports custom processor extensions\n",
    "\n",
    "3. **Annotation Module**\n",
    "   - Deep integration with Label Studio annotation platform\n",
    "   - Supports multiple preset annotation templates\n",
    "   - Automatic project creation and configuration management\n",
    "   - Supports multi-user collaborative annotation\n",
    "\n",
    "4. **Export Module**\n",
    "   - Multi-format data export: jsonl, parquet, json\n",
    "   - Intelligent data splitting (train/test sets)\n",
    "   - Maintains original data directory structure\n",
    "\n",
    "5. **Build Module**\n",
    "   - Unified data pipeline orchestration\n",
    "   - Automatic inter-module data flow management\n",
    "   - Supports YAML configuration-based building\n",
    "   - Supports pipeline reuse and extension\n",
    "\n",
    "## Operation Modes\n",
    "\n",
    "The Data Module supports two main operation methods: **Python Script Mode** and **YAML Configuration Mode**, catering to different user preferences.\n",
    "\n",
    "> **Reference Examples**\n",
    "\n",
    "### Python Script Mode (data_pipeline.py)\n",
    "\n",
    "For the complete pipeline script, please refer to `./examples/data/data_pipeline.py`\n",
    "\n",
    "#### 1. Basic Data Processing Flow\n",
    "Execute the complete data processing pipeline: **Data Loading → Data Processing → Data Export**\n",
    "\n",
    "```bash\n",
    "# Process 100 sample data points\n",
    "python data_pipeline.py --mode basic --limit 100\n",
    "```\n",
    "\n",
    "#### 2. Complete Flow with Annotation\n",
    "Execute the complete pipeline including manual annotation: **Data Loading → Data Processing → Data Annotation → Data Export**\n",
    "\n",
    "```bash\n",
    "# Requires Label Studio API Token\n",
    "python data_pipeline.py --mode annotation --api-token YOUR_LABEL_STUDIO_TOKEN\n",
    "```\n",
    "\n",
    "#### 3. Independent Module Testing Mode\n",
    "Supports testing individual module functionality:\n",
    "\n",
    "- **Load Only**: `python data_pipeline.py --mode load-only`\n",
    "- **Process Only**: `python data_pipeline.py --mode process-only`  \n",
    "- **Export Only**: `python data_pipeline.py --mode export-only`\n",
    "\n",
    "#### 4. Annotation Data Export Mode\n",
    "Export completed annotation data from Label Studio:\n",
    "\n",
    "```bash\n",
    "python data_pipeline.py --mode export-annotation \\\n",
    "    --api-token YOUR_TOKEN \\\n",
    "    --project-id PROJECT_ID\n",
    "```\n",
    "\n",
    "### YAML Configuration Mode (data_from_yaml.py)\n",
    "\n",
    "Run data pipelines through declarative YAML configuration files, more suitable for batch processing and production environments:\n",
    "\n",
    "```bash\n",
    "python data_from_yaml.py --config ./examples/data/config.yaml\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration File Details\n",
    "\n",
    "### YAML Configuration File Structure\n",
    "\n",
    "The YAML configuration file provides a declarative pipeline configuration approach, supporting complete data processing flow definition. Here's the complete configuration file structure explanation:\n",
    "\n",
    "```yaml\n",
    "dataset:\n",
    "    # Dataset basic information\n",
    "    name: rewardbench2                    # Dataset name\n",
    "                                          # local mode: custom name (e.g., rewardbench2)\n",
    "                                          # huggingface mode: HF dataset name (e.g., allenai/reward-bench-2)\n",
    "    \n",
    "    # Data source configuration\n",
    "    configs:\n",
    "        type: local                       # Data source type\n",
    "                                          # - local: Local file system\n",
    "                                          # - huggingface: HuggingFace Hub\n",
    "        source: rewardbench2              # Data source adapter identifier\n",
    "                                          # Note: Ensure corresponding converter is registered\n",
    "        path: /path/to/data.parquet       # Data file path (local mode only)\n",
    "        huggingface_split: train          # Data split name (huggingface mode only)\n",
    "                                          # Options: train, test, validation, etc.\n",
    "        limit: 2000                       # Sample count limit (random sampling)\n",
    "                                          # Used for quick testing or data preview\n",
    "    \n",
    "    # Data processor configuration (optional)\n",
    "    processors:\n",
    "        # Conversation turn filter\n",
    "        - type: filter\n",
    "          name: conversation_turn_filter\n",
    "          config:\n",
    "            min_turns: 1                  \n",
    "            max_turns: 6                  \n",
    "        \n",
    "        # Text length filter\n",
    "        - type: filter\n",
    "          name: text_length_filter\n",
    "          config:\n",
    "            min_length: 10                \n",
    "            max_length: 1000              \n",
    "        \n",
    "        # data-juicer operator example\n",
    "        - type: data_juicer\n",
    "          name: character_repetition_filter\n",
    "          config:\n",
    "            rep_len: 10                   \n",
    "            min_ratio: 0.0                \n",
    "            max_ratio: 0.5                \n",
    "    \n",
    "    # Annotation configuration (optional)\n",
    "    annotation:\n",
    "        template_name: \"rewardbench2\"     # Annotation template name\n",
    "        project_title: \"Reward Bench Evaluation\"  # Label Studio project title\n",
    "        project_description: \"Reward model evaluation using reward bench template from yaml\"\n",
    "        server_url: \"http://localhost:8080\"        # Label Studio server address\n",
    "        api_token: \"your_api_token_here\"          # Label Studio API token\n",
    "    \n",
    "    # Export configuration (required)\n",
    "    export:\n",
    "        output_dir: ./examples/data/exports       # Export directory path\n",
    "        formats: [\"jsonl\"]                        # Export format list\n",
    "                                                  # Supported: jsonl, parquet, json\n",
    "        preserve_structure: true                  # Whether to maintain original directory structure\n",
    "        split_ratio: {\"train\": 0.8, \"test\": 0.2} # Dataset split ratio\n",
    "                                                  # Supports multiple splits: train/test, comment out if no splitting needed\n",
    "    \n",
    "    # Metadata configuration (optional)\n",
    "    metadata:\n",
    "        source: \"rewardbench2\"            # Data source identifier\n",
    "        version: \"1.0\"                    # Data version (optional)\n",
    "        description: \"Sample dataset\"      # Data description (optional)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Resources\n",
    "\n",
    "### Official Documentation\n",
    "- **Label Studio Official Guide**: https://labelstud.io/guide/\n",
    "- **Data-Juicer Project Documentation**: https://github.com/modelscope/data-juicer\n",
    "- **HuggingFace Datasets**: https://huggingface.co/docs/datasets/\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
