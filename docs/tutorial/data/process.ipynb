{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Process Module\n",
    "\n",
    "## 1. Overview\n",
    "\n",
    "The Data Process Module provides users with a unified and flexible data processing solution. Based on the **Operator Pipeline** design philosophy, this module allows users to build complex data processing workflows by flexibly combining multiple operators.\n",
    "\n",
    "## 2. Architecture Design\n",
    "\n",
    "### Core Components\n",
    "\n",
    "#### 2.1. DataProcess - Data Processing Engine\n",
    "   - Inherits from `BaseDataModule`, providing standardized data processing interfaces\n",
    "   - Manages and orchestrates the execution order of operator sequences\n",
    "   - Supports both batch data processing and real-time data stream processing\n",
    "\n",
    "#### 2.2. BaseOperator - Abstract Base Class for Operators\n",
    "   - Defines standard interface specifications for operators\n",
    "   - Supports generic types for type safety\n",
    "   - Provides extensible data processing abstract methods\n",
    "\n",
    "#### 2.3. OperatorFactory - Operator Factory\n",
    "   - Implements unified registration and dynamic creation mechanisms for operators\n",
    "   - Seamlessly integrates with the data-juicer ecosystem operators\n",
    "   - Supports configuration-based operator instantiation\n",
    "\n",
    "## 3. Core Features\n",
    "\n",
    "### 3.1. Pipeline-based Data Processing\n",
    "- **Chain Operations**: Supports seamless serial execution of multiple operators\n",
    "- **Metadata Preservation**: Completely preserves metadata information from original datasets\n",
    "- **Full Tracking**: Provides detailed processing logs, performance statistics, and data flow tracking\n",
    "\n",
    "### 3.2. Rich Operator Ecosystem\n",
    "- **Built-in Operators**:\n",
    "  - `TextLengthFilter` - Intelligent filter based on text length\n",
    "  - `ConversationTurnFilter` - Filter for conversation turn count\n",
    "- **External Integration**:\n",
    "  - Full support for data-juicer operator library\n",
    "  - Support for custom operator extensions\n",
    "\n",
    "### 3.3. Configuration-driven Design\n",
    "- **Declarative Configuration**: Flexibly define data processing flows through configuration files\n",
    "- **Parameterized Control**: All operator parameters can be adjusted through configuration files\n",
    "- **Dynamic Adjustment**: Supports runtime dynamic modification of processing parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quick Start\n",
    "\n",
    "### Method 1: Direct Operator Creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xielipeng/Library/Caches/pypoetry/virtualenvs/rm-gallery-VQCvXsd2-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-02 13:24:02.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrm_gallery.core.utils.logger\u001b[0m:\u001b[36minit_logger\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mstart!\u001b[0m\n",
      "Before processing: 1000 data entries\u001b[32m2025-07-02 13:24:02.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrm_gallery.core.data.load.base\u001b[0m:\u001b[36m_load_data_impl\u001b[0m:\u001b[36m392\u001b[0m - \u001b[1mLoaded 1865 samples from file: ../../../data/reward-bench-2/data/test-00000-of-00001.parquet\u001b[0m\n",
      "\n",
      "After processing: 168 data entries\n",
      "\u001b[32m2025-07-02 13:24:02.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrm_gallery.core.data.load.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m262\u001b[0m - \u001b[1mApplied limit of 1000, final count: 1000\u001b[0m\n",
      "\u001b[32m2025-07-02 13:24:02.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrm_gallery.core.data.load.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m276\u001b[0m - \u001b[1mSuccessfully loaded 1000 items from rewardbench2\u001b[0m\n",
      "\u001b[32m2025-07-02 13:24:02.729\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrm_gallery.core.data.process.process\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mProcessing 1000 items with 2 operators\u001b[0m\n",
      "\u001b[32m2025-07-02 13:24:02.729\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrm_gallery.core.data.process.process\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mApplying operator 1/2: text_length_filter\u001b[0m\n",
      "\u001b[32m2025-07-02 13:24:02.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrm_gallery.core.data.process.process\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mOperator text_length_filter completed: 168 items remaining\u001b[0m\n",
      "\u001b[32m2025-07-02 13:24:02.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrm_gallery.core.data.process.process\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mApplying operator 2/2: conversation_turn_filter\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-02 13:24:02.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrm_gallery.core.data.process.process\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mOperator conversation_turn_filter completed: 168 items remaining\u001b[0m\n",
      "\u001b[32m2025-07-02 13:24:02.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrm_gallery.core.data.process.process\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1mProcessing completed: 1000 -> 168 items\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from rm_gallery.core.data.process.process import create_processor\n",
    "from rm_gallery.core.data.process.ops.filter.text_length_filter import TextLengthFilter\n",
    "from rm_gallery.core.data.process.ops.filter.conversation_turn_filter import ConversationTurnFilter\n",
    "from rm_gallery.core.data.load.base import create_loader\n",
    "import rm_gallery.core.data     # Core strategy registration\n",
    "import rm_gallery.gallery.data  # Extension strategy registration\n",
    "\n",
    "# Configure local file loading parameters\n",
    "config = {\n",
    "    \"path\": \"../../../data/reward-bench-2/data/test-00000-of-00001.parquet\",\n",
    "    \"limit\": 1000,  # Limit the number of data entries to load\n",
    "}\n",
    "\n",
    "# Create data loader\n",
    "loader = create_loader(\n",
    "    name=\"rewardbench2\",           # Dataset name\n",
    "    load_strategy_type=\"local\",    # Use local file loading strategy\n",
    "    data_source=\"rewardbench2\",    # Specify data source format converter\n",
    "    config=config                  # Pass configuration parameters\n",
    ")\n",
    "\n",
    "# Execute data loading\n",
    "dataset = loader.run()\n",
    "\n",
    "# Create operators\n",
    "text_filter = TextLengthFilter(\n",
    "    name=\"text_length_filter\",\n",
    "    config={\"min_length\": 50, \"max_length\": 2000}\n",
    ")\n",
    "\n",
    "turn_filter = ConversationTurnFilter(\n",
    "    name=\"conversation_turn_filter\", \n",
    "    config={\"min_turns\": 1, \"max_turns\": 10}\n",
    ")\n",
    "\n",
    "# Create data processing module\n",
    "processor = create_processor(\n",
    "    name=\"data_processor\",\n",
    "    operators=[text_filter, turn_filter]\n",
    ")\n",
    "\n",
    "# Process data\n",
    "result = processor.run(dataset)\n",
    "print(f\"Before processing: {len(dataset.datasamples)} data entries\")\n",
    "print(f\"After processing: {len(result.datasamples)} data entries\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Configuration-based Batch Processing\n",
    "\n",
    "Using configuration files provides more flexible definition of data processing workflows, especially suitable for complex multi-step processing scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create operators through configuration\n",
    "from rm_gallery.core.data.process.process import create_processor\n",
    "from rm_gallery.core.data.load.base import create_loader\n",
    "from rm_gallery.core.data.process.ops.base import OperatorFactory\n",
    "import rm_gallery.core.data     # Core strategy registration\n",
    "import rm_gallery.gallery.data  # Extension strategy registration\n",
    "\n",
    "# Configure local file loading parameters\n",
    "config = {\n",
    "    \"path\": \"../../../data/reward-bench-2/data/test-00000-of-00001.parquet\",\n",
    "    \"limit\": 1000,  # Limit the number of data entries to load\n",
    "}\n",
    "\n",
    "# Create data loader\n",
    "loader = create_loader(\n",
    "    name=\"rewardbench2\",           # Dataset name\n",
    "    load_strategy_type=\"local\",    # Use local file loading strategy\n",
    "    data_source=\"rewardbench2\",    # Specify data source format converter\n",
    "    config=config                  # Pass configuration parameters\n",
    ")\n",
    "\n",
    "# Execute data loading\n",
    "dataset = loader.run()\n",
    "\n",
    "# Configure multiple operators\n",
    "operator_configs = [\n",
    "    {\n",
    "        \"type\": \"filter\",\n",
    "        \"name\": \"conversation_turn_filter\",\n",
    "        \"config\": {\"min_turns\": 1, \"max_turns\": 8}\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"filter\",\n",
    "        \"name\": \"text_length_filter\", \n",
    "        \"config\": {\"min_length\": 100, \"max_length\": 2000}\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"data_juicer\",\n",
    "        \"name\": \"character_repetition_filter\",\n",
    "        \"config\": {\n",
    "            \"rep_len\": 10,\n",
    "            \"min_ratio\": 0.0,\n",
    "            \"max_ratio\": 0.5\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Batch create operators\n",
    "operators = [OperatorFactory.create_operator(config) for config in operator_configs]\n",
    "\n",
    "# Create processor\n",
    "processor = create_processor(\n",
    "    name=\"batch_processor\",\n",
    "    operators=operators\n",
    ")\n",
    "\n",
    "result = processor.run(dataset)\n",
    "print(f\"Before processing: {len(dataset.datasamples)} data entries\")\n",
    "print(f\"After processing: {len(result.datasamples)} data entries\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Features\n",
    "\n",
    "### 5.1. Custom Operator Development\n",
    "\n",
    "When built-in operators cannot meet specific requirements, you can easily create custom operators. Here's the complete development workflow:\n",
    "\n",
    "#### Step 1: Implement Operator Class\n",
    "\n",
    "Create custom operators in the `rm_gallery/gallery/data/process/` directory:\n",
    "\n",
    "```python\n",
    "from rm_gallery.core.data.process.ops.base import BaseOperator, OperatorFactory\n",
    "\n",
    "@OperatorFactory.register(\"custom_filter\")\n",
    "class CustomFilter(BaseOperator):\n",
    "    \"\"\"Custom data filter example\"\"\"\n",
    "    \n",
    "    def process_dataset(self, items):\n",
    "        \"\"\"\n",
    "        Core method for processing datasets\n",
    "        \n",
    "        Args:\n",
    "            items: List of input data items\n",
    "            \n",
    "        Returns:\n",
    "            List of filtered data items\n",
    "        \"\"\"\n",
    "        filtered_items = []\n",
    "        for item in items:\n",
    "            if self._custom_condition(item):\n",
    "                filtered_items.append(item)\n",
    "        return filtered_items\n",
    "    \n",
    "    def _custom_condition(self, item):\n",
    "        \"\"\"\n",
    "        Custom filtering condition\n",
    "        \n",
    "        Args:\n",
    "            item: Single data item\n",
    "            \n",
    "        Returns:\n",
    "            bool: Whether to keep this data item\n",
    "        \"\"\"\n",
    "        # Implement your filtering logic here\n",
    "        return True\n",
    "```\n",
    "\n",
    "#### Step 2: Register Operator\n",
    "\n",
    "Import the operator in `rm_gallery/gallery/data/__init__.py` to complete registration:\n",
    "\n",
    "```python\n",
    "from rm_gallery.gallery.data.process.custom_filter import CustomFilter\n",
    "```\n",
    "\n",
    "### 5.2. Data-Juicer Operator Integration\n",
    "\n",
    "RM-Gallery seamlessly integrates with the data-juicer ecosystem, allowing you to use its rich collection of data processing operators:\n",
    "\n",
    "```python\n",
    "# Configuration example using data-juicer operators\n",
    "config = {\n",
    "    \"type\": \"data_juicer\",\n",
    "    \"name\": \"text_length_filter\",\n",
    "    \"config\": {\n",
    "        \"min_len\": 10,\n",
    "        \"max_len\": 20\n",
    "    }\n",
    "}\n",
    "\n",
    "operator = OperatorFactory.create_operator(config)\n",
    "```\n",
    "\n",
    "## 6. Supported Operators\n",
    "\n",
    "### RM-Gallery Built-in Operators\n",
    "\n",
    "| Operator Name | Functionality | Configuration Parameters |\n",
    "|---------------|---------------|-------------------------|\n",
    "| `TextLengthFilter` | Filter data samples based on text length | `min_length`, `max_length` |\n",
    "| `ConversationTurnFilter` | Filter samples based on conversation turn count | `min_turns`, `max_turns` |\n",
    "\n",
    "### Data-Juicer Integrated Operators\n",
    "\n",
    "| Operator Name | Functionality | Status |\n",
    "|---------------|---------------|--------|\n",
    "| `text_length_filter` | Text length filtering | âœ… Tested |\n",
    "| `character_repetition_filter` | Character repetition filtering | âœ… Tested |\n",
    "| `word_repetition_filter` | Word repetition filtering | ðŸ”„ Testing |\n",
    "\n",
    "> **Tip**: We continuously add and test new operators, stay tuned for more features!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rm-gallery-VQCvXsd2-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
