dataset:
    name: "preference-test-sets"
    description: "Preference test dataset from Anthropic HHH"
    version: "1.0.0"
    configs:
        type: local # 必填
        source: rewardbench # 必填
        dimension: helpfulness # 可选，支持用户自定义评估维度，预制维度见data_schema.py
        path: /Users/xielipeng/RM-Gallery/data/preference-test-sets/data/anthropic_helpful-00000-of-00001.parquet #必填
        #limit: 2000 # 可选，随机采样数据集大小
    processors:
        - type: filter
          name: conversation_turn_filter
          config:
            min_turns: 2
            max_turns: 6
        - type: filter
          name: rm_text_length_filter
          config:
            min_length: 10
            max_length: 1000
        - type: data_juicer
          name: text_length_filter
          config:
            min_len: 50
            max_len: 100
        - type: group
          name: group_filter
          config:
            train_ratio: 0.7
            test_ratio: 0.3
    extra_metadata:
        source: "anthropic"
        task_type: "preference"


